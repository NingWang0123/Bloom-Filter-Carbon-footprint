{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import murmurhash3_32\n",
    "from random import randint\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets/URL_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "negative_sample = data.loc[(data['label'] == -1)]\n",
    "positive_sample = data.loc[(data['label'] == 1)]\n",
    "url_negative = negative_sample['url']\n",
    "url = positive_sample['url']\n",
    "n = len(url)\n",
    "train_negative = negative_sample.sample(frac = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfunc(m):\n",
    "    ss = randint(1, 99999999)\n",
    "    def hash_m(x):\n",
    "        return murmurhash3_32(x,seed=ss)%m\n",
    "    return hash_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###CPU\n",
    "class Ada_BloomFilter():\n",
    "    def __init__(self, n, hash_len, k_max):\n",
    "        self.n = n\n",
    "        self.hash_len = int(hash_len)\n",
    "        self.h = []\n",
    "        for i in range(int(k_max)):\n",
    "            self.h.append(hashfunc(self.hash_len))\n",
    "        self.table = np.zeros(self.hash_len, dtype=int)\n",
    "    def insert(self, key, k):\n",
    "        for j in range(int(k)):\n",
    "            t = self.h[j](key)\n",
    "            self.table[t] = 1\n",
    "    def test(self, key, k):\n",
    "        test_result = 0\n",
    "        match = 0\n",
    "        for j in range(int(k)):\n",
    "            t = self.h[j](key)\n",
    "            match += 1*(self.table[t] == 1)\n",
    "        if match == k:\n",
    "            test_result = 1\n",
    "        return test_result\n",
    "\n",
    "\n",
    "\n",
    "def R_size(count_key, count_nonkey, R0):\n",
    "    R = [0]*len(count_key)\n",
    "    R[0] = R0\n",
    "    for k in range(1, len(count_key)):\n",
    "        R[k] = max(int(count_key[k] * (np.log(count_nonkey[0]/count_nonkey[k])/np.log(0.618) + R[0]/count_key[0])), 1)\n",
    "    return R\n",
    "\n",
    "\n",
    "def Find_Optimal_Parameters(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample):\n",
    "    c_set = np.arange(c_min, c_max+10**(-6), 0.1)\n",
    "    FP_opt = train_negative.shape[0]\n",
    "\n",
    "    k_min = 0\n",
    "    for k_max in range(num_group_min, num_group_max+1):\n",
    "        for c in c_set:\n",
    "            tau = sum(c ** np.arange(0, k_max - k_min + 1, 1))\n",
    "            n = positive_sample.shape[0]\n",
    "            hash_len = R_sum\n",
    "            bloom_filter = Ada_BloomFilter(n, hash_len, k_max)\n",
    "            thresholds = np.zeros(k_max - k_min + 1)\n",
    "            thresholds[-1] = 1.1\n",
    "            num_negative = sum(train_negative['score'] <= thresholds[-1])\n",
    "            num_piece = int(num_negative / tau) + 1\n",
    "            score = train_negative.loc[(train_negative['score'] <= thresholds[-1]), 'score']\n",
    "            score = np.sort(score)\n",
    "            for k in range(k_min, k_max):\n",
    "                i = k - k_min\n",
    "                score_1 = score[score < thresholds[-(i + 1)]]\n",
    "                if int(num_piece * c ** i) < len(score_1):\n",
    "                    thresholds[-(i + 2)] = score_1[-int(num_piece * c ** i)]\n",
    "\n",
    "            url = positive_sample['url']\n",
    "            score = positive_sample['score']\n",
    "\n",
    "            for score_s, url_s in zip(score, url):\n",
    "                ix = min(np.where(score_s < thresholds)[0])\n",
    "                k = k_max - ix\n",
    "                bloom_filter.insert(url_s, k)\n",
    "            ML_positive = train_negative.loc[(train_negative['score'] >= thresholds[-2]), 'url']\n",
    "            url_negative = train_negative.loc[(train_negative['score'] < thresholds[-2]), 'url']\n",
    "            score_negative = train_negative.loc[(train_negative['score'] < thresholds[-2]), 'score']\n",
    "\n",
    "            test_result = np.zeros(len(url_negative))\n",
    "            ss = 0\n",
    "            for score_s, url_s in zip(score_negative, url_negative):\n",
    "                ix = min(np.where(score_s < thresholds)[0])\n",
    "                # thres = thresholds[ix]\n",
    "                k = k_max - ix\n",
    "                test_result[ss] = bloom_filter.test(url_s, k)\n",
    "                ss += 1\n",
    "            FP_items = sum(test_result) + len(ML_positive)\n",
    "            print('False positive items: %d, Number of groups: %d, c = %f' %(FP_items, k_max, round(c, 2)))\n",
    "\n",
    "            if FP_opt > FP_items:\n",
    "                FP_opt = FP_items\n",
    "                bloom_filter_opt = bloom_filter\n",
    "                thresholds_opt = thresholds\n",
    "                k_max_opt = k_max\n",
    "\n",
    "    # print('Optimal FPs: %f, Optimal c: %f, Optimal num_group: %d' % (FP_opt, c_opt, num_group_opt))\n",
    "    return bloom_filter_opt, thresholds_opt, k_max_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_min = 1.8\n",
    "c_max = 2.1\n",
    "num_group_min = 8\n",
    "num_group_max = 12\n",
    "R_sum = 200000\n",
    "\n",
    "bloom_filter_opt, thresholds_opt, k_max_opt = Find_Optimal_Parameters(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###GPU\n",
    "def hashfunc(m):\n",
    "    ss = randint(1, 99999999)\n",
    "    def hash_m(x):\n",
    "        # Assuming x is a string, convert to bytes for hashing\n",
    "        return murmurhash.mrmr.hash(x.encode('utf-8'), seed=ss) % m\n",
    "    return hash_m\n",
    "# def hashfunc(m):\n",
    "#     ss = randint(1, 99999999)\n",
    "#     def hash_m(x):\n",
    "#         return murmurhash3_32(x,seed=ss)%m\n",
    "#     return hash_m\n",
    "\n",
    "\n",
    "class Ada_BloomFilter():\n",
    "    def __init__(self, n, hash_len, k_max):\n",
    "        self.n = n\n",
    "        self.hash_len = int(hash_len)\n",
    "        self.h = [hashfunc(self.hash_len) for _ in range(k_max)]\n",
    "        # Initialize the table on GPU\n",
    "        self.table = torch.zeros(self.hash_len, dtype=torch.int32, device='cuda')\n",
    "    \n",
    "    def insert(self, keys):\n",
    "        positions = torch.zeros((len(keys), len(self.h)), dtype=torch.long, device='cuda')\n",
    "        for i, key in enumerate(keys):\n",
    "            for j, hash_func in enumerate(self.h):\n",
    "                positions[i, j] = hash_func(key)\n",
    "        # Flatten and remove duplicates before updating the table to prevent race conditions\n",
    "        positions = positions.view(-1).unique()\n",
    "        self.table[positions] = 1\n",
    "    \n",
    "    def test(self, keys):\n",
    "        results = torch.ones(len(keys), dtype=torch.int32, device='cuda')\n",
    "        for i, key in enumerate(keys):\n",
    "            for j, hash_func in enumerate(self.h):\n",
    "                if not self.table[hash_func(key)]:\n",
    "                    results[i] = 0\n",
    "                    break\n",
    "        return results\n",
    "\n",
    "def Find_Optimal_Parameters(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample):\n",
    "    c_set = torch.arange(c_min, c_max + 10**(-6), 0.1, device='cuda')\n",
    "    FP_opt = train_negative.shape[0]\n",
    "\n",
    "    for k_max in range(num_group_min, num_group_max + 1):\n",
    "        for c in c_set:\n",
    "            tau = torch.sum(c ** torch.arange(0, k_max + 1, device='cuda'))\n",
    "            n = positive_sample.shape[0]\n",
    "            hash_len = R_sum\n",
    "            bloom_filter = Ada_BloomFilter(n, hash_len, k_max)\n",
    "            thresholds = torch.zeros(k_max + 1, device='cuda')\n",
    "            thresholds[-1] = 1.1  # Define the initial threshold\n",
    "            num_negative = (train_negative['score'] <= thresholds[-1].item()).sum()\n",
    "            num_piece = int(num_negative / tau.item()) + 1\n",
    "            score = train_negative[train_negative['score'] <= thresholds[-1].item()]['score'].values\n",
    "            score = torch.tensor(np.sort(score), device='cuda')\n",
    "            for k in range(k_max):\n",
    "                i = k\n",
    "                score_1 = score[score < thresholds[-(i + 1)].item()]\n",
    "                if int(num_piece * c.item() ** i) < len(score_1):\n",
    "                    thresholds[-(i + 2)] = score_1[-int(num_piece * c.item() ** i)]\n",
    "\n",
    "            keys = [url_s for score_s, url_s in zip(positive_sample['score'].values, positive_sample['url']) if score_s < thresholds[0].item()]\n",
    "            bloom_filter.insert(keys)\n",
    "\n",
    "            ML_positive = train_negative.loc[(train_negative['score'] >= thresholds[-2]), 'url']\n",
    "            url_negative = train_negative[train_negative['score'] < thresholds[-2].item()]['url']\n",
    "            score_negative = train_negative[train_negative['score'] < thresholds[-2].item()]['score'].values\n",
    "            \n",
    "\n",
    "            test_keys = [url_s for score_s, url_s in zip(score_negative, url_negative) if score_s < thresholds[0].item()]\n",
    "            test_results = bloom_filter.test(test_keys)\n",
    "            FP_items = test_results.sum().item()+ len(ML_positive)\n",
    "            print(f'False positive items: {FP_items}, Number of groups: {k_max}, c = {round(c.item(), 2)}')\n",
    "\n",
    "            if FP_opt > FP_items:\n",
    "                FP_opt = FP_items\n",
    "                bloom_filter_opt = bloom_filter\n",
    "                thresholds_opt = thresholds\n",
    "                k_max_opt = k_max\n",
    "\n",
    "    return bloom_filter_opt, thresholds_opt, k_max_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m num_group_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m      5\u001b[0m R_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200000\u001b[39m\n\u001b[1;32m----> 7\u001b[0m bloom_filter_opt, thresholds_opt, k_max_opt \u001b[38;5;241m=\u001b[39m Find_Optimal_Parameters(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample)\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mFind_Optimal_Parameters\u001b[1;34m(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFind_Optimal_Parameters\u001b[39m(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample):\n\u001b[1;32m---> 42\u001b[0m     c_set \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(c_min, c_max \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m), \u001b[38;5;241m0.1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m     FP_opt \u001b[38;5;241m=\u001b[39m train_negative\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k_max \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_group_min, num_group_max \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "c_min = 1.8\n",
    "c_max = 2.1\n",
    "num_group_min = 8\n",
    "num_group_max = 12\n",
    "R_sum = 200000\n",
    "\n",
    "bloom_filter_opt, thresholds_opt, k_max_opt = Find_Optimal_Parameters(c_min, c_max, num_group_min, num_group_max, R_sum, train_negative, positive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.zeros(1).cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
